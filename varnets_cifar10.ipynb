{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "varnets_cifar10",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8adu+8tlctCZTFb8Xa0UD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e4a05719c0a4dc889aaab61604b8b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f034ad20400343719d4c4ef72205d78e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd0c2fee4c69448eae4be75df24c4ead",
              "IPY_MODEL_9a7d4e22812d41dd8aaa99b1f1060873"
            ]
          }
        },
        "f034ad20400343719d4c4ef72205d78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd0c2fee4c69448eae4be75df24c4ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e0a79185348473cb015268d4c380870",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b2a254fefc449298bec06b7641f60bc"
          }
        },
        "9a7d4e22812d41dd8aaa99b1f1060873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cd793ec3337406892fc8308ac34ec25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 102150285.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0005202b7bb4a459bc148a2ef20dd46"
          }
        },
        "6e0a79185348473cb015268d4c380870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b2a254fefc449298bec06b7641f60bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cd793ec3337406892fc8308ac34ec25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0005202b7bb4a459bc148a2ef20dd46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/james-simon/varnets/blob/master/varnets_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE-D3oGC1_S9"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import inspect\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "# from torch.nn.modules.utils import _single, _pair, _triple, _reverse_repeat_tuple\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_hWavyN2wlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105bbc6a-9f84-4e77-eab9-2ef1ee458e61"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 15\n",
        "N_WORKERS = 4\n",
        "\n",
        "IMG_SIZE = 32\n",
        "N_CLASSES = 10\n",
        "\n",
        "dataset_name = \"CIFAR10\"\n",
        "data_path = \"\"\n",
        "\n",
        "architecture = \"VGG\"\n",
        "\n",
        "optimizer_class = torch.optim.SGD\n",
        "LEARNING_RATE = 0.05\n",
        "MOMENTUM = .9\n",
        "\n",
        "# check device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"using \" + DEVICE)\n",
        "\n",
        "try:\n",
        "    latch\n",
        "except NameError:\n",
        "  old_linear_def = F.linear\n",
        "  old_conv_def = F.conv2d\n",
        "  old_relu_def = F.relu\n",
        "  print('latched')\n",
        "latch = True"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda\n",
            "latched\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wW4FOiYUyhC"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def all_parameters(model):\n",
        "  return torch.cat([p for p in model.parameters() if p.requires_grad])\n",
        "\n",
        "def sample_loader(loader, n_samples=1):\n",
        "  for x,_ in loader:\n",
        "    return(x[0:min(n_samples, x.size()[0])].to(DEVICE))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOjzIs26_I"
      },
      "source": [
        "## Dataset setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6jEBaF26cX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "5e4a05719c0a4dc889aaab61604b8b2a",
            "f034ad20400343719d4c4ef72205d78e",
            "bd0c2fee4c69448eae4be75df24c4ead",
            "9a7d4e22812d41dd8aaa99b1f1060873",
            "6e0a79185348473cb015268d4c380870",
            "8b2a254fefc449298bec06b7641f60bc",
            "3cd793ec3337406892fc8308ac34ec25",
            "a0005202b7bb4a459bc148a2ef20dd46"
          ]
        },
        "outputId": "8e18be43-44f6-4ed6-de99-caf0d1845261"
      },
      "source": [
        "transform_set_train = None\n",
        "transform_set_test = None\n",
        "\n",
        "if dataset_name == \"MNIST\":\n",
        "  transform_set_train = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "                                 transforms.ToTensor()])\n",
        "  transform_set_test = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "                                 transforms.ToTensor()])\n",
        "if dataset_name == \"CIFAR10\":\n",
        "  if architecture == \"ALEXNET\":\n",
        "    transform_set_train = transforms.Compose([transforms.Scale((224, 224)),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomCrop(32, padding=4),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                                          (0.2023, 0.1994, 0.2010))])\n",
        "    transform_set_test = transforms.Compose([transforms.Scale((224, 224)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                                        (0.2023, 0.1994, 0.2010))])\n",
        "  else:\n",
        "    transform_set_train = transforms.Compose([\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.RandomCrop(32, padding=4),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "    transform_set_test = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "\n",
        "ds = getattr(torchvision.datasets, dataset_name)\n",
        "dataset_path = os.path.join(data_path, dataset_name.lower())\n",
        "\n",
        "train_set = ds(dataset_path, train=True, download=True, transform=transform_set_train)\n",
        "test_set = ds(dataset_path, train=False, download=True, transform=transform_set_test)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, \n",
        "                          batch_size=BATCH_SIZE, \n",
        "                          shuffle=True,\n",
        "                          num_workers=N_WORKERS)\n",
        "test_loader = DataLoader(dataset=test_set, \n",
        "                          batch_size=BATCH_SIZE, \n",
        "                          shuffle=False,\n",
        "                          num_workers=N_WORKERS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e4a05719c0a4dc889aaab61604b8b2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting cifar10/cifar-10-python.tar.gz to cifar10\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8alR-7I5YIXo"
      },
      "source": [
        "## Train and test methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OvikG6QYHmF"
      },
      "source": [
        "def run_epoch(model, optimizer, criterion, device, loader, mode):\n",
        "  print(\"starting \" + mode + \"\\t\\t cuda using \" + str(torch.cuda.memory_allocated()/10**9) + \" GB\")\n",
        "\n",
        "  if mode == \"train\":\n",
        "    model.train()\n",
        "  elif mode == \"test\" or mode == \"eval\":\n",
        "    model.eval()\n",
        "  else:\n",
        "    print(\"INVALID MODE\")\n",
        "    assert(False)\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  for batch_i, (X, y) in enumerate(loader):\n",
        "\n",
        "    if mode == \"train\":\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_hat = model(X)\n",
        "    # y_hat = None\n",
        "    # if mode == \"train\":\n",
        "    #   y_hat = model(X)\n",
        "    # else:\n",
        "    #   with torch.no_grad():\n",
        "    #     y_hat = model(X)\n",
        "\n",
        "    loss = criterion(y_hat, y)\n",
        "\n",
        "    if mode == \"train\":\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    batch_loss = loss.item()*X.size(0)\n",
        "    epoch_loss += batch_loss\n",
        "\n",
        "    _, predicted_labels = torch.max(y_hat, 1)\n",
        "    batch_acc = (predicted_labels == y).sum().item()\n",
        "    epoch_acc += batch_acc\n",
        "  \n",
        "  epoch_loss /= len(loader.dataset)\n",
        "  epoch_acc /= len(loader.dataset)\n",
        "  return (epoch_loss, epoch_acc)\n",
        "\n",
        "def train(model, optimizer, criterion, device, train_loader, test_loader, n_epochs, print_every_n_epochs=1):\n",
        "    # set up optimization metrics\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      e_start_t = time.time()\n",
        "\n",
        "      # trainin'\n",
        "      tr_loss, tr_acc = run_epoch(model, optimizer, criterion, device, train_loader, \"train\")\n",
        "      train_losses.append(tr_loss)\n",
        "      train_accs.append(tr_acc)\n",
        "\n",
        "      # testin'\n",
        "      te_loss, te_acc = run_epoch(model, optimizer, criterion, device, test_loader, \"test\")\n",
        "      test_losses.append(te_loss)\n",
        "      test_accs.append(te_acc)\n",
        "\n",
        "      if epoch % print_every_n_epochs == (print_every_n_epochs - 1):\n",
        "          print(f'Epoch: {epoch}\\t'\n",
        "                f'Epoch time: {time.time() - e_start_t} --- '\n",
        "                f'Train loss: {tr_loss:.4f}\\t'\n",
        "                f'test loss: {te_loss:.4f}\\t'\n",
        "                f'Train accuracy: {100 * tr_acc:.2f}\\t'\n",
        "                f'test accuracy: {100 * te_acc:.2f}')\n",
        "          \n",
        "    return (train_accs, train_losses, test_accs, test_losses)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SCYibiK9J9F"
      },
      "source": [
        "## Define model initialization with w ~ N(0, 1/n) and b = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT-fV-M-6EJT"
      },
      "source": [
        "def initialize(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "      # w ~ N(0, 1/n)\n",
        "      # b = 0\n",
        "      n = m.weight.size()[1]*m.weight.size()[2]*m.weight.size()[3]\n",
        "      std = 1/n**(1/2)\n",
        "      nn.init.normal_(m.weight, std=std)\n",
        "      if m.bias is not None:\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "      nn.init.constant_(m.weight, 1)\n",
        "      nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "      # w ~ N(0, 1/n)\n",
        "      # b = 0\n",
        "      n = m.weight.size()[1]\n",
        "      std = 1/n**(1/2)\n",
        "      nn.init.normal_(m.weight, std=std)\n",
        "      nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkxQ8b9QWypo"
      },
      "source": [
        "## Define special varnet functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leDb-ZHgN02t"
      },
      "source": [
        "# E[|x|^a] where x ~ N(0, 1)\n",
        "def normal_distribution_moment(a):\n",
        "  return (2**(a/2))*math.gamma((a + 1)/2)/math.pi**(1/2)\n",
        "\n",
        "def power_series_var(terms):\n",
        "  total = 0\n",
        "  for (a0, b0, c0) in terms:\n",
        "    for (a1, b1, c1) in terms:\n",
        "      total += c0*c1*normal_distribution_moment(a0+a1)*normal_distribution_moment(b0+b1)\n",
        "  return (total)\n",
        "\n",
        "def normalize_terms(terms):\n",
        "  var = power_series_var(terms)\n",
        "  std = var**(1/2)\n",
        "  return ([(a, b, c/std) for (a, b, c) in terms])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXD3pHkQ7Qib"
      },
      "source": [
        "#a, b, c_ab\n",
        "terms = [(1, 1, 1), (3, 3, 1)]\n",
        "terms = normalize_terms(terms)\n",
        "\n",
        "def var_linear(input, weights, bias=None):\n",
        "  n = weights.size()[1]\n",
        "  sqrt_n = n**.5\n",
        "  \n",
        "  output = old_linear_def(torch.relu(input)**2/(torch.relu(input)+1), weights, bias)\n",
        "  output += (1/sqrt_n)*old_linear_def(torch.tanh(torch.relu(input)), torch.tanh(sqrt_n*weights), bias)\n",
        "\n",
        "  return output*1.5\n",
        "\n",
        "def var_conv2d(input, weights, bias=None, stride=(1,1), padding=(0,0), dilation=(1,1), groups=1):\n",
        "  n = weights.size()[1]*weights.size()[2]*weights.size()[3]\n",
        "  sqrt_n = n**.5\n",
        "\n",
        "  # if this is the first layer\n",
        "  if input.size()[1:] == torch.Size([3,32,32]):\n",
        "    output = old_conv_def(input, weights, bias, stride, padding, dilation, groups)\n",
        "    return output*1\n",
        "\n",
        "  output = old_conv_def(torch.relu(input)**2/(torch.relu(input)+1), weights, bias, stride, padding, dilation, groups)\n",
        "  output += (1/sqrt_n)*old_conv_def(torch.tanh(torch.relu(input)), torch.tanh(sqrt_n*weights), bias, stride, padding, dilation, groups)\n",
        "\n",
        "  return output*1.5\n",
        "\n",
        "# replace F methods with mult methods\n",
        "# F.linear = old_linear_def\n",
        "# F.conv2d = old_conv_def\n",
        "F.linear = var_linear\n",
        "F.conv2d = var_conv2d"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xt3oUrba5Z"
      },
      "source": [
        "def relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor:\n",
        "    result = torch.relu(input)\n",
        "    return result\n",
        "\n",
        "def identity(input: torch.Tensor, inplace: bool = False) -> torch.Tensor:\n",
        "    result = input\n",
        "    return result\n",
        "\n",
        "# redefine F.relu so that when torch.models.vgg19 calls nn.ReLU which calls F.relu, it finds this function instead\n",
        "F.relu = identity"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJjrPn-0GSKY",
        "outputId": "8438c495-29e9-493d-a73d-d0339eb18017"
      },
      "source": [
        "model = torchvision.models.vgg19(num_classes=10, init_weights=True).to(DEVICE)\n",
        "initialize(model)\n",
        "output = model(sample_loader(train_loader, n_samples=1))\n",
        "print(output)\n",
        "# output.sum().backward()\n",
        "\n",
        "mem_used = torch.cuda.memory_allocated()\n",
        "print(mem_used/10**9)\n",
        "\n",
        "del output\n",
        "torch.cuda.empty_cache()\n",
        "mem_used -= torch.cuda.memory_allocated()\n",
        "print(\"one forward pass uses \" + str(mem_used/10**9) + \" GB; that's a lot\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7108, -1.6850,  0.2018,  1.3550, -0.4648,  2.0402,  0.4250, -1.4768,\n",
            "         -0.2197,  0.8804]], device='cuda:0', grad_fn=<MulBackward0>)\n",
            "4.486951936\n",
            "one forward pass uses 0.566934016 GB; that's a lot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prbOlSUVsPCy"
      },
      "source": [
        "## Set up and run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXPk3m5rcf05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b59140d-9450-4b75-c498-a78ef590a2e7"
      },
      "source": [
        "def run_tests(n_trials=3, n_epochs=15, print_every=10**7):\n",
        "  global model\n",
        "  trajectories = []\n",
        "  for i in range(n_trials):\n",
        "    model = torchvision.models.vgg19(num_classes=10, init_weights=True).to(DEVICE)\n",
        "    initialize(model)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    traj = train(model, optimizer, criterion, DEVICE, train_loader, test_loader, n_epochs, print_every_n_epochs=1)\n",
        "    trajectories.append(traj)\n",
        "  return torch.tensor(trajectories)\n",
        "\n",
        "# STANDARD\n",
        "# print(\"STANDARD\")\n",
        "# F.linear = old_linear_def\n",
        "# F.conv2d = old_conv_def\n",
        "# F.relu = old_relu_def\n",
        "# LEARNING_RATE = .005\n",
        "# additive_results = run_tests(n_trials=1, n_epochs=50, print_every=1)\n",
        "# print(additive_results)\n",
        "\n",
        "# # WX + TANH(W)TANH(X)\n",
        "# print(\"WX + TANH(W)TANH(X)\")\n",
        "\n",
        "# WX + TANH(W)RELU(X)\n",
        "print(\"(1/sqrtN)*TANH(sqrtN*W)*TANH(X) + W*RELU(X)^2/(RELU(X) + 1)\")\n",
        "F.linear = var_linear\n",
        "F.conv2d = var_conv2d\n",
        "F.relu = identity\n",
        "LEARNING_RATE = .005\n",
        "var_results = run_tests(n_trials=1, n_epochs=100, print_every=1)\n",
        "print(var_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1/sqrtN)*TANH(sqrtN*W)*TANH(X) + W*RELU(X)^2/(RELU(X) + 1)\n",
            "starting train\t\t cuda using 3.92001792 GB\n",
            "starting test\t\t cuda using 5.041366528 GB\n",
            "Epoch: 0\tEpoch time: 110.54276156425476 --- Train loss: 2.3031\ttest loss: 2.3026\tTrain accuracy: 10.24\ttest accuracy: 10.00\n",
            "starting train\t\t cuda using 5.041366528 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gejPDIOwA_dt"
      },
      "source": [
        "W*RELU(X) with linear start | .005 | 100e | 1\n",
        "99.01/88.91\n",
        "\n",
        "W*RELU(X) with linear start | .001 | 100e | 1.4\n",
        "97.88/87.58\n",
        "\n",
        "W*RELU(X) with ELU(X) start | .005 | 100e | 1\n",
        "\n",
        "W*ELU(X) with linear start | .001 | 100e | 1.1\n",
        "99.10/85.67\n",
        "\n",
        "(1/sqrtN)*TANH(sqrtN*W)*TANH(X) + W*RELU(X) with linear start | .001 | 100e | .9\n",
        "99.16/86.92\n",
        "\n",
        "W*ELU(X) - (1/sqrtN)*TANH(sqrtN*W)RELU(X) with linear start | .001 | 100e | 2\n",
        "98.87/85.65\n",
        "\n",
        "W*TANH(X) with linear start | .001 | 100e | 1.1\n",
        "98.80/85.04\n",
        "\n",
        "W*MIN(X, SIN(X)) with linear start | .0001 | 100e | 1.1\n",
        "88.83/80.38\n",
        "\n",
        "W*TANH(RELU(X)) with linear start | .001 | 100e | 1.5\n",
        "running #3\n",
        "\n",
        "WX + TANH(W)RELU(X) with linear start | .0005 | 100e | .7\n",
        "98.13/84.53\n",
        "\n",
        "W*RELU(X)^2/(RELU(X) + 1) + (1/sqrtN)TANH(sqrtN*W)*TANH(RELU(X)) with linear start | .005 | 100e | 1.1\n",
        "running #1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}