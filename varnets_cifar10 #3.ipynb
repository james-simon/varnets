{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "varnets_cifar10 #3",
      "provenance": [],
      "authorship_tag": "ABX9TyMwVxnxLQNDFduzQ4AfILgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7145cb53762e47808c24f94f64b4b92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac39ac4512a9402a9b5988a8daf909f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_489e8319bced4423a81d84b5ed3fb174",
              "IPY_MODEL_7cfbdb0ce4dd4cac9e9f328d9d430612"
            ]
          }
        },
        "ac39ac4512a9402a9b5988a8daf909f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "489e8319bced4423a81d84b5ed3fb174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_587aee6b08d94f45b77aef49c7eef743",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5184b35100e74d50a1b88ea4fdc89394"
          }
        },
        "7cfbdb0ce4dd4cac9e9f328d9d430612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70aae32ae29d4a09aadae02490c000dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 54839313.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6d202f50aee4e0782f67b284853f6b3"
          }
        },
        "587aee6b08d94f45b77aef49c7eef743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5184b35100e74d50a1b88ea4fdc89394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70aae32ae29d4a09aadae02490c000dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6d202f50aee4e0782f67b284853f6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/james-simon/varnets/blob/master/varnets_cifar10%20%233.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_kRVlzm2w7a"
      },
      "source": [
        "## Imports and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE-D3oGC1_S9"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import inspect\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "# from torch.nn.modules.utils import _single, _pair, _triple, _reverse_repeat_tuple\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_hWavyN2wlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab511b79-1e8c-4441-b710-91374ea9ca4c"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 15\n",
        "N_WORKERS = 4\n",
        "\n",
        "IMG_SIZE = 32\n",
        "N_CLASSES = 10\n",
        "\n",
        "dataset_name = \"CIFAR10\"\n",
        "data_path = \"\"\n",
        "\n",
        "architecture = \"VGG\"\n",
        "\n",
        "optimizer_class = torch.optim.SGD\n",
        "LEARNING_RATE = 0.05\n",
        "MOMENTUM = .9\n",
        "\n",
        "# check device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"using \" + DEVICE)\n",
        "\n",
        "try:\n",
        "    latch\n",
        "except NameError:\n",
        "  old_linear_def = F.linear\n",
        "  old_conv_def = F.conv2d\n",
        "  old_relu_def = F.relu\n",
        "  print('latched')\n",
        "latch = True"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda\n",
            "latched\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wW4FOiYUyhC"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def all_parameters(model):\n",
        "  return torch.cat([p for p in model.parameters() if p.requires_grad])\n",
        "\n",
        "def sample_loader(loader, n_samples=1):\n",
        "  for x,_ in loader:\n",
        "    return(x[0:min(n_samples, x.size()[0])].to(DEVICE))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOjzIs26_I"
      },
      "source": [
        "## Dataset setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6jEBaF26cX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "7145cb53762e47808c24f94f64b4b92d",
            "ac39ac4512a9402a9b5988a8daf909f1",
            "489e8319bced4423a81d84b5ed3fb174",
            "7cfbdb0ce4dd4cac9e9f328d9d430612",
            "587aee6b08d94f45b77aef49c7eef743",
            "5184b35100e74d50a1b88ea4fdc89394",
            "70aae32ae29d4a09aadae02490c000dd",
            "d6d202f50aee4e0782f67b284853f6b3"
          ]
        },
        "outputId": "62fc478f-75d2-4276-9b4b-7c194818fa44"
      },
      "source": [
        "transform_set_train = None\n",
        "transform_set_test = None\n",
        "\n",
        "if dataset_name == \"MNIST\":\n",
        "  transform_set_train = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "                                 transforms.ToTensor()])\n",
        "  transform_set_test = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "                                 transforms.ToTensor()])\n",
        "if dataset_name == \"CIFAR10\":\n",
        "  if architecture == \"ALEXNET\":\n",
        "    transform_set_train = transforms.Compose([transforms.Scale((224, 224)),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomCrop(32, padding=4),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                                          (0.2023, 0.1994, 0.2010))])\n",
        "    transform_set_test = transforms.Compose([transforms.Scale((224, 224)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                                        (0.2023, 0.1994, 0.2010))])\n",
        "  else:\n",
        "    transform_set_train = transforms.Compose([\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.RandomCrop(32, padding=4),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "    transform_set_test = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                ])\n",
        "\n",
        "ds = getattr(torchvision.datasets, dataset_name)\n",
        "dataset_path = os.path.join(data_path, dataset_name.lower())\n",
        "\n",
        "train_set = ds(dataset_path, train=True, download=True, transform=transform_set_train)\n",
        "test_set = ds(dataset_path, train=False, download=True, transform=transform_set_test)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, \n",
        "                          batch_size=BATCH_SIZE, \n",
        "                          shuffle=True,\n",
        "                          num_workers=N_WORKERS)\n",
        "test_loader = DataLoader(dataset=test_set, \n",
        "                          batch_size=BATCH_SIZE, \n",
        "                          shuffle=False,\n",
        "                          num_workers=N_WORKERS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7145cb53762e47808c24f94f64b4b92d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting cifar10/cifar-10-python.tar.gz to cifar10\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8alR-7I5YIXo"
      },
      "source": [
        "## Train and test methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OvikG6QYHmF"
      },
      "source": [
        "def run_epoch(model, optimizer, criterion, device, loader, mode):\n",
        "  print(\"starting \" + mode + \"\\t\\t cuda using \" + str(torch.cuda.memory_allocated()/10**9) + \" GB\")\n",
        "\n",
        "  if mode == \"train\":\n",
        "    model.train()\n",
        "  elif mode == \"test\" or mode == \"eval\":\n",
        "    model.eval()\n",
        "  else:\n",
        "    print(\"INVALID MODE\")\n",
        "    assert(False)\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  for batch_i, (X, y) in enumerate(loader):\n",
        "\n",
        "    if mode == \"train\":\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_hat = model(X)\n",
        "    # y_hat = None\n",
        "    # if mode == \"train\":\n",
        "    #   y_hat = model(X)\n",
        "    # else:\n",
        "    #   with torch.no_grad():\n",
        "    #     y_hat = model(X)\n",
        "\n",
        "    loss = criterion(y_hat, y)\n",
        "\n",
        "    if mode == \"train\":\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    batch_loss = loss.item()*X.size(0)\n",
        "    epoch_loss += batch_loss\n",
        "\n",
        "    _, predicted_labels = torch.max(y_hat, 1)\n",
        "    batch_acc = (predicted_labels == y).sum().item()\n",
        "    epoch_acc += batch_acc\n",
        "  \n",
        "  epoch_loss /= len(loader.dataset)\n",
        "  epoch_acc /= len(loader.dataset)\n",
        "  return (epoch_loss, epoch_acc)\n",
        "\n",
        "def train(model, optimizer, criterion, device, train_loader, test_loader, n_epochs, print_every_n_epochs=1):\n",
        "    # set up optimization metrics\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      e_start_t = time.time()\n",
        "\n",
        "      # trainin'\n",
        "      tr_loss, tr_acc = run_epoch(model, optimizer, criterion, device, train_loader, \"train\")\n",
        "      train_losses.append(tr_loss)\n",
        "      train_accs.append(tr_acc)\n",
        "\n",
        "      # testin'\n",
        "      te_loss, te_acc = run_epoch(model, optimizer, criterion, device, test_loader, \"test\")\n",
        "      test_losses.append(te_loss)\n",
        "      test_accs.append(te_acc)\n",
        "\n",
        "      if epoch % print_every_n_epochs == (print_every_n_epochs - 1):\n",
        "          print(f'Epoch: {epoch}\\t'\n",
        "                f'Epoch time: {time.time() - e_start_t} --- '\n",
        "                f'Train loss: {tr_loss:.4f}\\t'\n",
        "                f'test loss: {te_loss:.4f}\\t'\n",
        "                f'Train accuracy: {100 * tr_acc:.2f}\\t'\n",
        "                f'test accuracy: {100 * te_acc:.2f}')\n",
        "          \n",
        "    return (train_accs, train_losses, test_accs, test_losses)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SCYibiK9J9F"
      },
      "source": [
        "## Define model initialization with w ~ N(0, 1/n) and b = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT-fV-M-6EJT"
      },
      "source": [
        "def initialize(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "      # w ~ N(0, 1/n)\n",
        "      # b = 0\n",
        "      n = m.weight.size()[1]*m.weight.size()[2]*m.weight.size()[3]\n",
        "      std = 1/n**(1/2)\n",
        "      nn.init.normal_(m.weight, std=std)\n",
        "      if m.bias is not None:\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "      nn.init.constant_(m.weight, 1)\n",
        "      nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "      # w ~ N(0, 1/n)\n",
        "      # b = 0\n",
        "      n = m.weight.size()[1]\n",
        "      std = 1/n**(1/2)\n",
        "      nn.init.normal_(m.weight, std=std)\n",
        "      nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkxQ8b9QWypo"
      },
      "source": [
        "## Define special varnet functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leDb-ZHgN02t"
      },
      "source": [
        "# E[|x|^a] where x ~ N(0, 1)\n",
        "def normal_distribution_moment(a):\n",
        "  return (2**(a/2))*math.gamma((a + 1)/2)/math.pi**(1/2)\n",
        "\n",
        "def power_series_var(terms):\n",
        "  total = 0\n",
        "  for (a0, b0, c0) in terms:\n",
        "    for (a1, b1, c1) in terms:\n",
        "      total += c0*c1*normal_distribution_moment(a0+a1)*normal_distribution_moment(b0+b1)\n",
        "  return (total)\n",
        "\n",
        "def normalize_terms(terms):\n",
        "  var = power_series_var(terms)\n",
        "  std = var**(1/2)\n",
        "  return ([(a, b, c/std) for (a, b, c) in terms])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXD3pHkQ7Qib"
      },
      "source": [
        "#a, b, c_ab\n",
        "terms = [(1, 1, 1), (3, 3, 1)]\n",
        "terms = normalize_terms(terms)\n",
        "\n",
        "def var_linear(input, weights, bias=None):\n",
        "  n = weights.size()[1]\n",
        "  sqrt_n = n**.5\n",
        "\n",
        "  # input_pow = torch.sign(input)*torch.abs(input)\n",
        "  # weights_pow = torch.sign(weights)*torch.abs(weights)\n",
        "  # output = old_linear_def(input_pow, weights_pow, bias)\n",
        "  # # output = old_linear_def(torch.sign(input)*torch.abs(input), torch.sign(weights)*torch.abs(weights), bias)\n",
        "  # return output\n",
        "  \n",
        "  # output = None\n",
        "  # for (a, b, c) in terms:\n",
        "  #   if output is None:\n",
        "  #     output = (n**((a-1)/2))*c*old_linear_def(torch.sign(input)*torch.abs(input)**a, torch.sign(weights)*torch.abs(weights)**b, bias)\n",
        "  #   else:\n",
        "  #     output += (n**((a-1)/2))*c*old_linear_def(torch.sign(input)*torch.abs(input)**a, torch.sign(weights)*torch.abs(weights)**b, bias)\n",
        "  # return output\n",
        "\n",
        "  # if this is the last layer\n",
        "  # if output.size()[1:] == torch.Size([N_CLASSES]):\n",
        "  \n",
        "  output = old_linear_def(input*torch.sigmoid(input), weights, bias)\n",
        "  # output = (1/sqrt_n)*old_linear_def(torch.relu(input), torch.tanh(sqrt_n*weights), bias)\n",
        "  # output += old_linear_def(torch.relu(input), torch.relu(weights), bias)\n",
        "  # output += -old_linear_def(torch.relu(-input), torch.relu(-weights), bias)\n",
        "  return output*1.55\n",
        "\n",
        "def var_conv2d(input, weights, bias=None, stride=(1,1), padding=(0,0), dilation=(1,1), groups=1):\n",
        "  n = weights.size()[1]*weights.size()[2]*weights.size()[3]\n",
        "  sqrt_n = n**.5\n",
        "\n",
        "  # output = None\n",
        "  # for (a, b, c) in terms:\n",
        "  #   if output is None:\n",
        "  #     output = (n**((a-1)/2))*c*old_conv_def(torch.sign(input)*torch.abs(input)**a, torch.sign(weights)*torch.abs(weights)**b, bias, stride, padding, dilation, groups)\n",
        "  #   else:\n",
        "  #     output += (n**((a-1)/2))*c*old_conv_def(torch.sign(input)*torch.abs(input)**a, torch.sign(weights)*torch.abs(weights)**b, bias, stride, padding, dilation, groups)\n",
        "  # return output\n",
        "\n",
        "  # if this is the first layer\n",
        "  if input.size()[1:] == torch.Size([3,32,32]):\n",
        "    output = old_conv_def(input, weights, bias, stride, padding, dilation, groups)\n",
        "    return output\n",
        "\n",
        "  output = old_conv_def(input*torch.sigmoid(input), weights, bias, stride, padding, dilation, groups)\n",
        "  # output = (1/sqrt_n)*old_conv_def(torch.relu(input), torch.tanh(sqrt_n*weights), bias, stride, padding, dilation, groups)\n",
        "  # output += old_conv_def(torch.relu(input), torch.relu(weights), bias, stride, padding, dilation, groups)\n",
        "  # output += -old_conv_def(torch.relu(-input), torch.relu(-weights), bias, stride, padding, dilation, groups)\n",
        "  return output*1.55\n",
        "\n",
        "# replace F methods with mult methods\n",
        "# F.linear = old_linear_def\n",
        "# F.conv2d = old_conv_def\n",
        "F.linear = var_linear\n",
        "F.conv2d = var_conv2d"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xt3oUrba5Z"
      },
      "source": [
        "def relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor:\n",
        "    result = torch.relu(input)\n",
        "    return result\n",
        "\n",
        "def identity(input: torch.Tensor, inplace: bool = False) -> torch.Tensor:\n",
        "    result = input\n",
        "    return result\n",
        "\n",
        "# redefine F.relu so that when torch.models.vgg19 calls nn.ReLU which calls F.relu, it finds this function instead\n",
        "F.relu = identity"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJjrPn-0GSKY",
        "outputId": "1d8ba287-88c7-43f2-dfd5-6dc10b48184f"
      },
      "source": [
        "model = torchvision.models.vgg19(num_classes=10, init_weights=True).to(DEVICE)\n",
        "initialize(model)\n",
        "output = model(sample_loader(train_loader, n_samples=1))\n",
        "print(output)\n",
        "# output.sum().backward()\n",
        "\n",
        "mem_used = torch.cuda.memory_allocated()\n",
        "print(mem_used/10**9)\n",
        "\n",
        "del output\n",
        "torch.cuda.empty_cache()\n",
        "mem_used -= torch.cuda.memory_allocated()\n",
        "print(\"one forward pass uses \" + str(mem_used/10**9) + \" GB; that's a lot\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1958, -0.2991,  0.2843,  0.0182,  0.2952, -0.8678,  0.0081, -0.1001,\n",
            "         -0.1212, -0.1272]], device='cuda:0', grad_fn=<MulBackward0>)\n",
            "2.24520448\n",
            "one forward pass uses 0.00367872 GB; that's a lot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prbOlSUVsPCy"
      },
      "source": [
        "## Set up and run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXPk3m5rcf05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af77094e-c9b9-4d79-f287-e75c4c780824"
      },
      "source": [
        "def run_tests(n_trials=3, n_epochs=15, print_every=10**7):\n",
        "  global model\n",
        "  trajectories = []\n",
        "  for i in range(n_trials):\n",
        "    model = torchvision.models.vgg19(num_classes=10, init_weights=True).to(DEVICE)\n",
        "    initialize(model)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    traj = train(model, optimizer, criterion, DEVICE, train_loader, test_loader, 100, print_every_n_epochs=1)\n",
        "    trajectories.append(traj)\n",
        "  return torch.tensor(trajectories)\n",
        "\n",
        "# STANDARD\n",
        "# print(\"STANDARD\")\n",
        "# F.linear = old_linear_def\n",
        "# F.conv2d = old_conv_def\n",
        "# F.relu = old_relu_def\n",
        "# LEARNING_RATE = .005\n",
        "# additive_results = run_tests(n_trials=1, n_epochs=50, print_every=1)\n",
        "# print(additive_results)\n",
        "\n",
        "# # WX + TANH(W)TANH(X)\n",
        "# print(\"WX + TANH(W)TANH(X)\")\n",
        "\n",
        "# WX + TANH(W)RELU(X)\n",
        "print(\"W*SWISH(X)\")\n",
        "F.linear = var_linear\n",
        "F.conv2d = var_conv2d\n",
        "F.relu = identity\n",
        "LEARNING_RATE = .001\n",
        "var_results = run_tests(n_trials=1, n_epochs=50, print_every=1)\n",
        "print(var_results)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W*SWISH(X)\n",
            "starting train\t\t cuda using 2.241656832 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 0\tEpoch time: 34.55834197998047 --- Train loss: 2.0712\ttest loss: 1.7496\tTrain accuracy: 22.34\ttest accuracy: 36.28\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 1\tEpoch time: 34.73185110092163 --- Train loss: 1.6142\ttest loss: 1.4131\tTrain accuracy: 40.06\ttest accuracy: 47.19\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 2\tEpoch time: 34.568833351135254 --- Train loss: 1.3946\ttest loss: 1.2269\tTrain accuracy: 48.58\ttest accuracy: 55.18\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 3\tEpoch time: 34.73529863357544 --- Train loss: 1.2492\ttest loss: 1.1218\tTrain accuracy: 54.45\ttest accuracy: 59.72\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 4\tEpoch time: 34.582592248916626 --- Train loss: 1.1266\ttest loss: 1.0228\tTrain accuracy: 59.42\ttest accuracy: 63.28\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 5\tEpoch time: 34.79181981086731 --- Train loss: 1.0309\ttest loss: 0.9287\tTrain accuracy: 63.04\ttest accuracy: 67.06\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 6\tEpoch time: 34.67299771308899 --- Train loss: 0.9387\ttest loss: 0.8438\tTrain accuracy: 66.60\ttest accuracy: 70.14\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 7\tEpoch time: 34.65322494506836 --- Train loss: 0.8629\ttest loss: 0.8050\tTrain accuracy: 69.47\ttest accuracy: 72.10\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 8\tEpoch time: 34.66385245323181 --- Train loss: 0.8032\ttest loss: 0.8027\tTrain accuracy: 71.64\ttest accuracy: 71.93\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 9\tEpoch time: 34.67421555519104 --- Train loss: 0.7513\ttest loss: 0.7289\tTrain accuracy: 73.46\ttest accuracy: 74.88\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 10\tEpoch time: 34.5474693775177 --- Train loss: 0.6955\ttest loss: 0.6791\tTrain accuracy: 75.43\ttest accuracy: 76.28\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 11\tEpoch time: 34.75773906707764 --- Train loss: 0.6572\ttest loss: 0.6696\tTrain accuracy: 76.90\ttest accuracy: 76.86\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 12\tEpoch time: 34.78005123138428 --- Train loss: 0.6250\ttest loss: 0.7072\tTrain accuracy: 78.06\ttest accuracy: 75.82\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 13\tEpoch time: 34.72877788543701 --- Train loss: 0.5848\ttest loss: 0.6103\tTrain accuracy: 79.75\ttest accuracy: 79.13\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 14\tEpoch time: 34.77964210510254 --- Train loss: 0.5533\ttest loss: 0.6318\tTrain accuracy: 80.61\ttest accuracy: 78.88\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 15\tEpoch time: 34.75474834442139 --- Train loss: 0.5283\ttest loss: 0.5880\tTrain accuracy: 81.37\ttest accuracy: 79.89\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 16\tEpoch time: 34.76014685630798 --- Train loss: 0.5013\ttest loss: 0.5843\tTrain accuracy: 82.30\ttest accuracy: 80.08\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 17\tEpoch time: 34.7540864944458 --- Train loss: 0.4774\ttest loss: 0.5596\tTrain accuracy: 83.29\ttest accuracy: 81.06\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 18\tEpoch time: 34.7864773273468 --- Train loss: 0.4497\ttest loss: 0.5500\tTrain accuracy: 84.27\ttest accuracy: 81.43\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 19\tEpoch time: 34.637930393218994 --- Train loss: 0.4376\ttest loss: 0.5473\tTrain accuracy: 84.56\ttest accuracy: 81.75\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 20\tEpoch time: 34.81416869163513 --- Train loss: 0.4115\ttest loss: 0.5243\tTrain accuracy: 85.43\ttest accuracy: 82.68\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 21\tEpoch time: 34.95604920387268 --- Train loss: 0.3942\ttest loss: 0.5438\tTrain accuracy: 86.36\ttest accuracy: 82.54\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 22\tEpoch time: 34.77697277069092 --- Train loss: 0.3730\ttest loss: 0.5437\tTrain accuracy: 86.85\ttest accuracy: 82.05\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 23\tEpoch time: 34.816566705703735 --- Train loss: 0.3609\ttest loss: 0.5211\tTrain accuracy: 87.40\ttest accuracy: 82.59\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 24\tEpoch time: 34.819581508636475 --- Train loss: 0.3418\ttest loss: 0.5294\tTrain accuracy: 88.04\ttest accuracy: 82.53\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 25\tEpoch time: 34.83293271064758 --- Train loss: 0.3231\ttest loss: 0.5247\tTrain accuracy: 88.69\ttest accuracy: 83.44\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 26\tEpoch time: 34.658162117004395 --- Train loss: 0.3098\ttest loss: 0.5268\tTrain accuracy: 89.25\ttest accuracy: 82.90\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 27\tEpoch time: 34.75133466720581 --- Train loss: 0.2958\ttest loss: 0.5307\tTrain accuracy: 89.71\ttest accuracy: 84.17\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 28\tEpoch time: 34.69647288322449 --- Train loss: 0.2792\ttest loss: 0.5506\tTrain accuracy: 90.25\ttest accuracy: 82.48\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 29\tEpoch time: 34.80608820915222 --- Train loss: 0.2705\ttest loss: 0.5701\tTrain accuracy: 90.50\ttest accuracy: 82.92\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 30\tEpoch time: 34.82296848297119 --- Train loss: 0.2540\ttest loss: 0.5536\tTrain accuracy: 91.10\ttest accuracy: 83.67\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 31\tEpoch time: 34.67336130142212 --- Train loss: 0.2446\ttest loss: 0.5281\tTrain accuracy: 91.57\ttest accuracy: 83.85\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 32\tEpoch time: 34.71470093727112 --- Train loss: 0.2319\ttest loss: 0.5431\tTrain accuracy: 91.84\ttest accuracy: 83.87\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 33\tEpoch time: 34.80318880081177 --- Train loss: 0.2268\ttest loss: 0.5376\tTrain accuracy: 92.00\ttest accuracy: 84.25\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 34\tEpoch time: 34.803083419799805 --- Train loss: 0.2133\ttest loss: 0.5529\tTrain accuracy: 92.53\ttest accuracy: 83.86\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 35\tEpoch time: 34.736122131347656 --- Train loss: 0.2059\ttest loss: 0.5469\tTrain accuracy: 92.71\ttest accuracy: 83.96\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 36\tEpoch time: 34.963698863983154 --- Train loss: 0.1900\ttest loss: 0.5781\tTrain accuracy: 93.27\ttest accuracy: 83.84\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 37\tEpoch time: 34.89057993888855 --- Train loss: 0.1797\ttest loss: 0.5688\tTrain accuracy: 93.67\ttest accuracy: 84.63\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 38\tEpoch time: 34.87617492675781 --- Train loss: 0.1783\ttest loss: 0.5407\tTrain accuracy: 93.71\ttest accuracy: 84.87\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 39\tEpoch time: 34.95020413398743 --- Train loss: 0.1644\ttest loss: 0.5733\tTrain accuracy: 94.24\ttest accuracy: 84.75\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 40\tEpoch time: 34.87090992927551 --- Train loss: 0.1626\ttest loss: 0.5675\tTrain accuracy: 94.27\ttest accuracy: 84.64\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 41\tEpoch time: 34.6639404296875 --- Train loss: 0.1521\ttest loss: 0.5595\tTrain accuracy: 94.70\ttest accuracy: 84.76\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 42\tEpoch time: 34.76500844955444 --- Train loss: 0.1446\ttest loss: 0.6015\tTrain accuracy: 94.81\ttest accuracy: 84.46\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 43\tEpoch time: 34.7886438369751 --- Train loss: 0.1375\ttest loss: 0.5852\tTrain accuracy: 95.20\ttest accuracy: 85.09\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 44\tEpoch time: 34.739229679107666 --- Train loss: 0.1309\ttest loss: 0.6062\tTrain accuracy: 95.40\ttest accuracy: 84.88\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 45\tEpoch time: 34.61040759086609 --- Train loss: 0.1254\ttest loss: 0.5975\tTrain accuracy: 95.46\ttest accuracy: 84.67\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 46\tEpoch time: 34.78478288650513 --- Train loss: 0.1196\ttest loss: 0.6522\tTrain accuracy: 95.82\ttest accuracy: 84.40\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 47\tEpoch time: 34.67731332778931 --- Train loss: 0.1190\ttest loss: 0.6384\tTrain accuracy: 95.75\ttest accuracy: 84.78\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 48\tEpoch time: 34.5425181388855 --- Train loss: 0.1108\ttest loss: 0.6443\tTrain accuracy: 96.16\ttest accuracy: 85.15\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 49\tEpoch time: 34.57045531272888 --- Train loss: 0.1079\ttest loss: 0.6214\tTrain accuracy: 96.21\ttest accuracy: 85.08\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 50\tEpoch time: 34.63713097572327 --- Train loss: 0.0968\ttest loss: 0.6889\tTrain accuracy: 96.54\ttest accuracy: 84.72\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 51\tEpoch time: 34.59156084060669 --- Train loss: 0.0971\ttest loss: 0.6376\tTrain accuracy: 96.58\ttest accuracy: 85.45\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 52\tEpoch time: 34.68471169471741 --- Train loss: 0.0956\ttest loss: 0.5966\tTrain accuracy: 96.64\ttest accuracy: 85.73\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 53\tEpoch time: 34.85383439064026 --- Train loss: 0.0884\ttest loss: 0.6816\tTrain accuracy: 96.92\ttest accuracy: 85.31\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 54\tEpoch time: 34.717272996902466 --- Train loss: 0.0866\ttest loss: 0.6481\tTrain accuracy: 96.98\ttest accuracy: 85.37\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 55\tEpoch time: 34.88451886177063 --- Train loss: 0.0813\ttest loss: 0.6784\tTrain accuracy: 97.25\ttest accuracy: 85.06\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 56\tEpoch time: 34.75056338310242 --- Train loss: 0.0780\ttest loss: 0.6692\tTrain accuracy: 97.29\ttest accuracy: 85.53\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 57\tEpoch time: 34.88247990608215 --- Train loss: 0.0706\ttest loss: 0.6837\tTrain accuracy: 97.52\ttest accuracy: 85.41\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 58\tEpoch time: 34.59952402114868 --- Train loss: 0.0764\ttest loss: 0.6356\tTrain accuracy: 97.30\ttest accuracy: 85.83\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 59\tEpoch time: 34.72366452217102 --- Train loss: 0.0702\ttest loss: 0.6535\tTrain accuracy: 97.61\ttest accuracy: 85.71\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 60\tEpoch time: 34.702497243881226 --- Train loss: 0.0657\ttest loss: 0.6677\tTrain accuracy: 97.64\ttest accuracy: 85.53\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 61\tEpoch time: 34.7473726272583 --- Train loss: 0.0645\ttest loss: 0.6818\tTrain accuracy: 97.77\ttest accuracy: 85.57\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 62\tEpoch time: 34.712915658950806 --- Train loss: 0.0594\ttest loss: 0.7098\tTrain accuracy: 97.90\ttest accuracy: 85.49\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 63\tEpoch time: 34.7827308177948 --- Train loss: 0.0571\ttest loss: 0.6760\tTrain accuracy: 98.01\ttest accuracy: 85.72\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 64\tEpoch time: 34.749940633773804 --- Train loss: 0.0555\ttest loss: 0.6961\tTrain accuracy: 98.04\ttest accuracy: 85.88\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 65\tEpoch time: 34.69268727302551 --- Train loss: 0.0552\ttest loss: 0.7035\tTrain accuracy: 98.08\ttest accuracy: 85.78\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 66\tEpoch time: 34.94024062156677 --- Train loss: 0.0554\ttest loss: 0.6940\tTrain accuracy: 98.05\ttest accuracy: 85.71\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 67\tEpoch time: 34.68253421783447 --- Train loss: 0.0543\ttest loss: 0.6605\tTrain accuracy: 98.11\ttest accuracy: 85.96\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 68\tEpoch time: 34.56273031234741 --- Train loss: 0.0522\ttest loss: 0.7518\tTrain accuracy: 98.19\ttest accuracy: 85.24\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 69\tEpoch time: 34.63784217834473 --- Train loss: 0.0478\ttest loss: 0.7226\tTrain accuracy: 98.31\ttest accuracy: 85.83\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 70\tEpoch time: 34.936607122421265 --- Train loss: 0.0488\ttest loss: 0.7481\tTrain accuracy: 98.37\ttest accuracy: 85.68\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 71\tEpoch time: 34.719149112701416 --- Train loss: 0.0444\ttest loss: 0.7126\tTrain accuracy: 98.51\ttest accuracy: 85.48\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 72\tEpoch time: 34.839922189712524 --- Train loss: 0.0458\ttest loss: 0.7074\tTrain accuracy: 98.40\ttest accuracy: 85.75\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 73\tEpoch time: 34.87170624732971 --- Train loss: 0.0418\ttest loss: 0.7348\tTrain accuracy: 98.51\ttest accuracy: 86.21\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 74\tEpoch time: 34.582427978515625 --- Train loss: 0.0423\ttest loss: 0.7695\tTrain accuracy: 98.50\ttest accuracy: 85.65\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 75\tEpoch time: 34.73638939857483 --- Train loss: 0.0389\ttest loss: 0.7763\tTrain accuracy: 98.62\ttest accuracy: 85.52\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 76\tEpoch time: 34.834068775177 --- Train loss: 0.0408\ttest loss: 0.7540\tTrain accuracy: 98.59\ttest accuracy: 85.86\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 77\tEpoch time: 34.928544998168945 --- Train loss: 0.0402\ttest loss: 0.7136\tTrain accuracy: 98.63\ttest accuracy: 85.91\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 78\tEpoch time: 34.79707074165344 --- Train loss: 0.0368\ttest loss: 0.7768\tTrain accuracy: 98.74\ttest accuracy: 85.88\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 79\tEpoch time: 34.71714520454407 --- Train loss: 0.0370\ttest loss: 0.7543\tTrain accuracy: 98.73\ttest accuracy: 85.77\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 80\tEpoch time: 34.8696928024292 --- Train loss: 0.0360\ttest loss: 0.7669\tTrain accuracy: 98.73\ttest accuracy: 85.78\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 81\tEpoch time: 34.84992337226868 --- Train loss: 0.0346\ttest loss: 0.7339\tTrain accuracy: 98.79\ttest accuracy: 86.19\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 82\tEpoch time: 34.63422226905823 --- Train loss: 0.0352\ttest loss: 0.7237\tTrain accuracy: 98.80\ttest accuracy: 85.94\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 83\tEpoch time: 34.72279930114746 --- Train loss: 0.0296\ttest loss: 0.7850\tTrain accuracy: 98.96\ttest accuracy: 85.95\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 84\tEpoch time: 34.647868156433105 --- Train loss: 0.0328\ttest loss: 0.7486\tTrain accuracy: 98.86\ttest accuracy: 86.27\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 85\tEpoch time: 34.83306932449341 --- Train loss: 0.0325\ttest loss: 0.7468\tTrain accuracy: 98.92\ttest accuracy: 86.22\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 86\tEpoch time: 34.87324643135071 --- Train loss: 0.0295\ttest loss: 0.7546\tTrain accuracy: 99.00\ttest accuracy: 86.25\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 87\tEpoch time: 34.79083442687988 --- Train loss: 0.0291\ttest loss: 0.7803\tTrain accuracy: 98.98\ttest accuracy: 86.58\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 88\tEpoch time: 34.85224270820618 --- Train loss: 0.0295\ttest loss: 0.7723\tTrain accuracy: 98.96\ttest accuracy: 86.02\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 89\tEpoch time: 34.980387926101685 --- Train loss: 0.0298\ttest loss: 0.7543\tTrain accuracy: 99.01\ttest accuracy: 86.36\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 90\tEpoch time: 34.95407176017761 --- Train loss: 0.0281\ttest loss: 0.8107\tTrain accuracy: 99.03\ttest accuracy: 86.32\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 91\tEpoch time: 35.02484750747681 --- Train loss: 0.0257\ttest loss: 0.7752\tTrain accuracy: 99.13\ttest accuracy: 86.72\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 92\tEpoch time: 35.17922878265381 --- Train loss: 0.0262\ttest loss: 0.8478\tTrain accuracy: 99.05\ttest accuracy: 86.08\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 93\tEpoch time: 35.08211874961853 --- Train loss: 0.0256\ttest loss: 0.7823\tTrain accuracy: 99.10\ttest accuracy: 86.52\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 94\tEpoch time: 34.89504551887512 --- Train loss: 0.0272\ttest loss: 0.7898\tTrain accuracy: 99.10\ttest accuracy: 86.22\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 95\tEpoch time: 35.03624963760376 --- Train loss: 0.0260\ttest loss: 0.7955\tTrain accuracy: 99.11\ttest accuracy: 86.22\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 96\tEpoch time: 34.94652009010315 --- Train loss: 0.0262\ttest loss: 0.8072\tTrain accuracy: 99.16\ttest accuracy: 86.19\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 97\tEpoch time: 35.09422445297241 --- Train loss: 0.0238\ttest loss: 0.7720\tTrain accuracy: 99.18\ttest accuracy: 86.40\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 98\tEpoch time: 35.046428203582764 --- Train loss: 0.0213\ttest loss: 0.8312\tTrain accuracy: 99.25\ttest accuracy: 86.34\n",
            "starting train\t\t cuda using 3.362219008 GB\n",
            "starting test\t\t cuda using 3.362219008 GB\n",
            "Epoch: 99\tEpoch time: 35.053428411483765 --- Train loss: 0.0222\ttest loss: 0.8021\tTrain accuracy: 99.24\ttest accuracy: 86.52\n",
            "tensor([[[0.2234, 0.4006, 0.4858, 0.5445, 0.5942, 0.6304, 0.6660, 0.6947,\n",
            "          0.7164, 0.7346, 0.7543, 0.7690, 0.7806, 0.7975, 0.8061, 0.8137,\n",
            "          0.8230, 0.8329, 0.8427, 0.8456, 0.8543, 0.8636, 0.8685, 0.8740,\n",
            "          0.8804, 0.8869, 0.8925, 0.8971, 0.9025, 0.9050, 0.9110, 0.9157,\n",
            "          0.9184, 0.9200, 0.9253, 0.9271, 0.9327, 0.9367, 0.9371, 0.9424,\n",
            "          0.9427, 0.9470, 0.9481, 0.9520, 0.9540, 0.9546, 0.9582, 0.9575,\n",
            "          0.9616, 0.9621, 0.9654, 0.9658, 0.9664, 0.9692, 0.9698, 0.9725,\n",
            "          0.9729, 0.9752, 0.9730, 0.9761, 0.9764, 0.9777, 0.9790, 0.9801,\n",
            "          0.9804, 0.9808, 0.9805, 0.9811, 0.9819, 0.9831, 0.9837, 0.9851,\n",
            "          0.9840, 0.9851, 0.9850, 0.9862, 0.9859, 0.9863, 0.9874, 0.9873,\n",
            "          0.9873, 0.9879, 0.9880, 0.9896, 0.9886, 0.9892, 0.9900, 0.9898,\n",
            "          0.9896, 0.9901, 0.9903, 0.9913, 0.9905, 0.9910, 0.9910, 0.9911,\n",
            "          0.9916, 0.9918, 0.9925, 0.9924],\n",
            "         [2.0712, 1.6142, 1.3946, 1.2492, 1.1266, 1.0309, 0.9387, 0.8629,\n",
            "          0.8032, 0.7513, 0.6955, 0.6572, 0.6250, 0.5848, 0.5533, 0.5283,\n",
            "          0.5013, 0.4774, 0.4497, 0.4376, 0.4115, 0.3942, 0.3730, 0.3609,\n",
            "          0.3418, 0.3231, 0.3098, 0.2958, 0.2792, 0.2705, 0.2540, 0.2446,\n",
            "          0.2319, 0.2268, 0.2133, 0.2059, 0.1900, 0.1797, 0.1783, 0.1644,\n",
            "          0.1626, 0.1521, 0.1446, 0.1375, 0.1309, 0.1254, 0.1196, 0.1190,\n",
            "          0.1108, 0.1079, 0.0968, 0.0971, 0.0956, 0.0884, 0.0866, 0.0813,\n",
            "          0.0780, 0.0706, 0.0764, 0.0702, 0.0657, 0.0645, 0.0594, 0.0571,\n",
            "          0.0555, 0.0552, 0.0554, 0.0543, 0.0522, 0.0478, 0.0488, 0.0444,\n",
            "          0.0458, 0.0418, 0.0423, 0.0389, 0.0408, 0.0402, 0.0368, 0.0370,\n",
            "          0.0360, 0.0346, 0.0352, 0.0296, 0.0328, 0.0325, 0.0295, 0.0291,\n",
            "          0.0295, 0.0298, 0.0281, 0.0257, 0.0262, 0.0256, 0.0272, 0.0260,\n",
            "          0.0262, 0.0238, 0.0213, 0.0222],\n",
            "         [0.3628, 0.4719, 0.5518, 0.5972, 0.6328, 0.6706, 0.7014, 0.7210,\n",
            "          0.7193, 0.7488, 0.7628, 0.7686, 0.7582, 0.7913, 0.7888, 0.7989,\n",
            "          0.8008, 0.8106, 0.8143, 0.8175, 0.8268, 0.8254, 0.8205, 0.8259,\n",
            "          0.8253, 0.8344, 0.8290, 0.8417, 0.8248, 0.8292, 0.8367, 0.8385,\n",
            "          0.8387, 0.8425, 0.8386, 0.8396, 0.8384, 0.8463, 0.8487, 0.8475,\n",
            "          0.8464, 0.8476, 0.8446, 0.8509, 0.8488, 0.8467, 0.8440, 0.8478,\n",
            "          0.8515, 0.8508, 0.8472, 0.8545, 0.8573, 0.8531, 0.8537, 0.8506,\n",
            "          0.8553, 0.8541, 0.8583, 0.8571, 0.8553, 0.8557, 0.8549, 0.8572,\n",
            "          0.8588, 0.8578, 0.8571, 0.8596, 0.8524, 0.8583, 0.8568, 0.8548,\n",
            "          0.8575, 0.8621, 0.8565, 0.8552, 0.8586, 0.8591, 0.8588, 0.8577,\n",
            "          0.8578, 0.8619, 0.8594, 0.8595, 0.8627, 0.8622, 0.8625, 0.8658,\n",
            "          0.8602, 0.8636, 0.8632, 0.8672, 0.8608, 0.8652, 0.8622, 0.8622,\n",
            "          0.8619, 0.8640, 0.8634, 0.8652],\n",
            "         [1.7496, 1.4131, 1.2269, 1.1218, 1.0228, 0.9287, 0.8438, 0.8050,\n",
            "          0.8027, 0.7289, 0.6791, 0.6696, 0.7072, 0.6103, 0.6318, 0.5880,\n",
            "          0.5843, 0.5596, 0.5500, 0.5473, 0.5243, 0.5438, 0.5437, 0.5211,\n",
            "          0.5294, 0.5247, 0.5268, 0.5307, 0.5506, 0.5701, 0.5536, 0.5281,\n",
            "          0.5431, 0.5376, 0.5529, 0.5469, 0.5781, 0.5688, 0.5407, 0.5733,\n",
            "          0.5675, 0.5595, 0.6015, 0.5852, 0.6062, 0.5975, 0.6522, 0.6384,\n",
            "          0.6443, 0.6214, 0.6889, 0.6376, 0.5966, 0.6816, 0.6481, 0.6784,\n",
            "          0.6692, 0.6837, 0.6356, 0.6535, 0.6677, 0.6818, 0.7098, 0.6760,\n",
            "          0.6961, 0.7035, 0.6940, 0.6605, 0.7518, 0.7226, 0.7481, 0.7126,\n",
            "          0.7074, 0.7348, 0.7695, 0.7763, 0.7540, 0.7136, 0.7768, 0.7543,\n",
            "          0.7669, 0.7339, 0.7237, 0.7850, 0.7486, 0.7468, 0.7546, 0.7803,\n",
            "          0.7723, 0.7543, 0.8107, 0.7752, 0.8478, 0.7823, 0.7898, 0.7955,\n",
            "          0.8072, 0.7720, 0.8312, 0.8021]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg0zGAPdpKOS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}